{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6fc4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… After SMOTE - Fraud cases: 79608\n",
      "Training XGBoost...\n",
      "Training LightGBM...\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 79608, number of negative: 159216\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8417\n",
      "[LightGBM] [Info] Number of data points in the train set: 238824, number of used features: 34\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.992506\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.993709\n",
      "Training Random Forest...\n",
      "Training Isolation Forest...\n",
      "Training Autoencoder...\n",
      "\n",
      "========================================\n",
      "Evaluating xgboost\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.82      0.82      0.82       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.91      0.91      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Confusion Matrix:\n",
      " [[85268    27]\n",
      " [   27   121]]\n",
      "F1 Score: 0.8176\n",
      "\n",
      "========================================\n",
      "Evaluating lightgbm\n",
      "========================================\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     85295\n",
      "           1       0.16      0.82      0.27       148\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.58      0.91      0.63     85443\n",
      "weighted avg       1.00      0.99      0.99     85443\n",
      "\n",
      "Confusion Matrix:\n",
      " [[84662   633]\n",
      " [   26   122]]\n",
      "F1 Score: 0.2702\n",
      "\n",
      "========================================\n",
      "Evaluating random_forest\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.70      0.82      0.75       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.85      0.91      0.88     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Confusion Matrix:\n",
      " [[85243    52]\n",
      " [   27   121]]\n",
      "F1 Score: 0.7539\n",
      "\n",
      "========================================\n",
      "Evaluating isolation_forest\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     85295\n",
      "           1       0.07      0.46      0.12       148\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.54      0.72      0.56     85443\n",
      "weighted avg       1.00      0.99      0.99     85443\n",
      "\n",
      "Confusion Matrix:\n",
      " [[84414   881]\n",
      " [   80    68]]\n",
      "F1 Score: 0.1240\n",
      "\n",
      "========================================\n",
      "Evaluating autoencoder\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     85295\n",
      "           1       0.00      0.00      0.00       148\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.50      0.49      0.50     85443\n",
      "weighted avg       1.00      0.99      0.99     85443\n",
      "\n",
      "Confusion Matrix:\n",
      " [[84440   855]\n",
      " [  148     0]]\n",
      "F1 Score: 0.0000\n",
      "\n",
      "ðŸ”¹ Ensemble Results\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.76      0.80      0.78       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.88      0.90      0.89     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "âœ… Models saved to ../models/\n",
      "ðŸ§© Processor saved to ../models/preprocessor.pkl\n",
      "âœ… All models and processor saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kulde\\fraud-detection-system\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # go one level up to project root\n",
    "\n",
    "from src.preprocessing import FraudDataProcessor\n",
    "from src.models import FraudDetectionModels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize\n",
    "processor = FraudDataProcessor()\n",
    "fraud_models = FraudDetectionModels()\n",
    "\n",
    "# Load data\n",
    "X_train, X_test, y_train, y_test = processor.load_and_split('../data/creditcard.csv')\n",
    "\n",
    "# Feature engineering\n",
    "X_train = processor.engineer_features(X_train)\n",
    "X_test = processor.engineer_features(X_test)\n",
    "\n",
    "# Split validation set\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# Balance training data\n",
    "X_res, y_res = processor.apply_smote(X_train_split, y_train_split)\n",
    "\n",
    "# Train models\n",
    "fraud_models.train_xgboost(X_res, y_res, X_val, y_val)\n",
    "fraud_models.train_lightgbm(X_res, y_res, X_val, y_val)\n",
    "fraud_models.train_random_forest(X_res, y_res)\n",
    "fraud_models.train_isolation_forest(X_train_split[y_train_split == 0])\n",
    "fraud_models.train_autoencoder(X_train_split[y_train_split == 0], X_val)\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in fraud_models.models.items():\n",
    "    fraud_models.evaluate_model(model, X_test, y_test, name)\n",
    "\n",
    "# Ensemble prediction\n",
    "print(\"\\nðŸ”¹ Ensemble Results\")\n",
    "ensemble_pred = fraud_models.ensemble_predict(X_test)\n",
    "print(classification_report(y_test, ensemble_pred))\n",
    "\n",
    "# Save everything\n",
    "fraud_models.save_models()\n",
    "processor.save_processor('../models/preprocessor.pkl')\n",
    "print(\"âœ… All models and processor saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48bc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
